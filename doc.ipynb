{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from embeddings_reproduction import embedding_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, k, window, modeldir_path): # X是样本名称\n",
    "    name_list = [X, str(k), str(window)]\n",
    "    if os.path.isfile('_'.join(name_list) + '.pkl'):\n",
    "        return\n",
    "    print('X\\t\\tk\\twindow')\n",
    "    print(name_list[0] + '\\t\\t' + '\\t'.join(name_list[1:]))\n",
    "    kmer_hypers = {'k':k, \n",
    "                   'overlap':False,\n",
    "                   'merge':False}\n",
    "    model_hypers = {'vector_size': 64,\n",
    "                    'min_count': 0,\n",
    "                    'epochs': 25,\n",
    "                    'window':window,\n",
    "                    'workers': 4} # 添加随机种子\n",
    "    documents = embedding_tools.Corpus(sequence_dict[X], kmer_hypers)\n",
    "    print(documents)\n",
    "    model = Doc2Vec(**model_hypers)\n",
    "    model.build_vocab(documents)\n",
    "    model.train(documents,total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    model.save(modeldir_path + '_'.join(name_list) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vectors(df, model, k, dest_file, overlap=False, method=None):\n",
    "    # df = pd.read_csv(data)\n",
    "    seqs = embedding_tools.get_seqs(df)\n",
    "    if method is not None:\n",
    "        seqs = embedding_tools.randomize_seqs(seqs, method=method) # 随机化序列\n",
    "    embeds = embedding_tools.get_embeddings_new(model, seqs, k=k,\n",
    "                                                overlap=overlap)\n",
    "    embeds = pd.DataFrame(embeds, index=df.index)\n",
    "    terms = list(range(embeds.shape[1]))\n",
    "    name = model.split('\\\\')[-1]\n",
    "    with open(dest_file + 'X_' + name, 'wb') as f:\n",
    "        pickle.dump((embeds, terms), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_path ='H:\\BLOOD_Task\\mixdata\\multi-ISTH-RJ.csv' \n",
    "mutdata = pd.read_csv(mut_path)\n",
    "mutsites = mutdata['Amino Acid Substitution']\n",
    "fstdir_path = 'H:\\BLOOD_Task\\mixdata\\FASTA'\n",
    "\n",
    "def get_fasta(mutsites,fstdir_path):\n",
    "    sequence = []\n",
    "    sequence_dict = {}\n",
    "    for mutsite in mutsites:\n",
    "        fasta_path = fstdir_path + '\\\\vWF_' + mutsite + '.fasta'\n",
    "        with open(fasta_path, 'r') as opf:\n",
    "            sequence.append(opf.read().split('\\n')[1])\n",
    "    sequence_dict['vWF'] = pd.DataFrame({'mutsite':mutsites,'sequence':sequence})\n",
    "    return sequence_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vWF':     mutsite                                           sequence\n",
       " 0      G19R  MIPARFAGVLLALALILPRTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " 1      D47H  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " 2      S49R  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " 3      S85P  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " 4     L129M  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " ..      ...                                                ...\n",
       " 288  L2617M  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " 289  P2628P  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " 290  L2702P  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " 291  G2705R  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " 292  C2750Y  MIPARFAGVLLALALILPGTLCAEGTRGRSSTARCSLFGSDFVNTF...\n",
       " \n",
       " [293 rows x 2 columns]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_dict = get_fasta(mutsites,fstdir_path)\n",
    "sequence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\t\tk\twindow\n",
      "vWF\t\t1\t1\n",
      "<embeddings_reproduction.embedding_tools.Corpus object at 0x0000015ACB56BBE0>\n",
      "X\t\tk\twindow\n",
      "vWF\t\t1\t2\n",
      "<embeddings_reproduction.embedding_tools.Corpus object at 0x0000015ACC792B80>\n",
      "X\t\tk\twindow\n",
      "vWF\t\t1\t3\n",
      "<embeddings_reproduction.embedding_tools.Corpus object at 0x0000015ACC010E50>\n",
      "X\t\tk\twindow\n",
      "vWF\t\t1\t4\n",
      "<embeddings_reproduction.embedding_tools.Corpus object at 0x0000015ACC792B80>\n",
      "X\t\tk\twindow\n",
      "vWF\t\t1\t5\n",
      "<embeddings_reproduction.embedding_tools.Corpus object at 0x0000015ACB7A3400>\n",
      "X\t\tk\twindow\n",
      "vWF\t\t1\t6\n",
      "<embeddings_reproduction.embedding_tools.Corpus object at 0x0000015ACB795FD0>\n",
      "X\t\tk\twindow\n",
      "vWF\t\t1\t7\n",
      "<embeddings_reproduction.embedding_tools.Corpus object at 0x0000015ACC792B80>\n"
     ]
    }
   ],
   "source": [
    "X = 'vWF'\n",
    "modeldir_path = 'H:\\BLOOD_Task\\mixdata\\doc\\\\vwF_model\\\\'\n",
    "for k in range(1,2):\n",
    "    for window in range(1,8):\n",
    "        train(X,k,window,modeldir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = os.listdir('H:\\BLOOD_Task\\mixdata\\doc\\\\vwF_model\\\\')\n",
    "models = [m for m in models if m[-3:] == 'pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n",
      "Inferring...\n"
     ]
    }
   ],
   "source": [
    "dest = 'H:\\BLOOD_Task\\mixdata\\doc\\\\' + X + '_embeddings\\\\'\n",
    "for model in models:\n",
    "    k = int(model[-7])\n",
    "    print('Inferring...')\n",
    "    infer_vectors(sequence_dict['vWF'], 'H:\\BLOOD_Task\\mixdata\\doc\\\\vwF_model\\\\'+ model, k, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带入多标签的训练模型尝试训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           0         1         2         3         4         5         6   \\\n",
       " 0   -0.067734  0.043939  0.050996 -0.078280  0.043260  0.134887  0.019991   \n",
       " 1   -0.027166  0.150776 -0.006376 -0.084445  0.033147  0.126106 -0.012924   \n",
       " 2   -0.080785  0.040340  0.017973 -0.072143  0.047508  0.138301  0.021396   \n",
       " 3   -0.029599  0.175719 -0.011658 -0.047247  0.035556  0.135953 -0.003931   \n",
       " 4   -0.095703  0.073214 -0.003976 -0.025609  0.029893  0.127486 -0.015924   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 288 -0.086131  0.144778 -0.015277 -0.076415  0.060201  0.142823 -0.009647   \n",
       " 289 -0.122592  0.124922  0.005250 -0.040201  0.053257  0.126796  0.027786   \n",
       " 290 -0.079587  0.089508 -0.029105 -0.054867  0.042508  0.112346  0.007114   \n",
       " 291 -0.128343  0.096922  0.020772 -0.039588  0.093079  0.095187 -0.003901   \n",
       " 292 -0.046974  0.116484  0.009552 -0.091489  0.083511  0.076209 -0.012418   \n",
       " \n",
       "            7         8         9   ...        54        55        56  \\\n",
       " 0   -0.159192 -0.057574 -0.000132  ...  0.068326 -0.096648  0.199807   \n",
       " 1   -0.172699 -0.040334 -0.006019  ...  0.052459 -0.054908  0.187222   \n",
       " 2   -0.201166 -0.044374  0.002838  ...  0.042354 -0.023519  0.214571   \n",
       " 3   -0.158166 -0.062994 -0.023092  ...  0.042158 -0.100994  0.167043   \n",
       " 4   -0.160490 -0.053428 -0.016350  ...  0.084178 -0.071715  0.234582   \n",
       " ..        ...       ...       ...  ...       ...       ...       ...   \n",
       " 288 -0.184276 -0.058599 -0.068418  ...  0.069181 -0.094649  0.183763   \n",
       " 289 -0.131310 -0.104313 -0.011130  ...  0.107120 -0.022777  0.183934   \n",
       " 290 -0.239726 -0.059606 -0.080550  ...  0.068173 -0.063894  0.158996   \n",
       " 291 -0.219698 -0.041261 -0.005673  ...  0.050724 -0.076923  0.201634   \n",
       " 292 -0.211985 -0.060972 -0.040433  ...  0.042674 -0.115681  0.219476   \n",
       " \n",
       "            57        58        59        60        61        62        63  \n",
       " 0   -0.076387  0.146979  0.225153  0.001098 -0.140986  0.195249 -0.068940  \n",
       " 1   -0.079114  0.178227  0.150480 -0.004914 -0.207282  0.247939 -0.040896  \n",
       " 2   -0.061808  0.118854  0.184144  0.016896 -0.197517  0.266147 -0.023244  \n",
       " 3   -0.069561  0.133453  0.155713  0.035936 -0.143800  0.221556  0.003889  \n",
       " 4   -0.058484  0.118471  0.173666  0.046246 -0.126275  0.256622 -0.060851  \n",
       " ..        ...       ...       ...       ...       ...       ...       ...  \n",
       " 288 -0.038629  0.116293  0.125389  0.021588 -0.156551  0.293481 -0.048692  \n",
       " 289 -0.064754  0.137622  0.211084  0.047746 -0.120712  0.263660 -0.020519  \n",
       " 290 -0.059431  0.153716  0.147227  0.096616 -0.166322  0.281774 -0.078052  \n",
       " 291 -0.102781  0.108674  0.222692  0.072294 -0.181033  0.228514 -0.051888  \n",
       " 292 -0.058146  0.088684  0.192416  0.034361 -0.140069  0.244074  0.003434  \n",
       " \n",
       " [293 rows x 64 columns],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "path='H:\\BLOOD_Task\\mixdata\\doc\\\\vwF_embeddings\\X_vWF_1_1.pkl'   # pkl文件所在路径,注意：应是多个文件\n",
    "\n",
    "with open(path,'rb') as f:\n",
    "    data = pickle.load(f)    # data[0]是要的数据\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "\n",
    "num = data[0].index\n",
    "trainval_idx,test_idx = train_test_split(num,test_size=0.2,random_state=0)\n",
    "train_idx,valid_idx = train_test_split(trainval_idx,test_size=0.2,random_state=0)\n",
    "\n",
    "mut_path ='H:\\BLOOD_Task\\mixdata\\multi-ISTH-RJ.csv' \n",
    "mutdata = pd.read_csv(mut_path)\n",
    "target = pd.DataFrame({'class_0':mutdata['class_0'],\n",
    "                       'class_1':mutdata['class_1'],\n",
    "                       'class_2':mutdata['class_2'],\n",
    "                       'class_3':mutdata['class_3'],\n",
    "                       'class_4':mutdata['class_4'],\n",
    "                       'class_5':mutdata['class_5']}) # Y\n",
    "\n",
    "\n",
    "X_trainval = data[0].loc[trainval_idx]\n",
    "X_test = data[0].loc[test_idx]\n",
    "\n",
    "y_trainval = target.loc[trainval_idx]\n",
    "y_test = target.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [08:02<00:00, 13.78s/it]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skmultilearn.adapt import MLkNN\n",
    "import numpy as np \n",
    "from scipy import sparse\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #忽略不重要的warning\n",
    "\n",
    "veclst = os.listdir('H:\\BLOOD_Task\\mixdata\\doc\\\\vwF_embeddings\\\\')\n",
    "test_score = []\n",
    "\n",
    "for vec in tqdm.tqdm(veclst):\n",
    "    vec_path = 'H:\\BLOOD_Task\\mixdata\\doc\\\\vwF_embeddings\\\\' + str(vec)\n",
    "    with open(vec_path,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    num = data[0].index\n",
    "    trainval_idx,test_idx = train_test_split(num,test_size=0.2,random_state=0)\n",
    "    train_idx,valid_idx = train_test_split(trainval_idx,test_size=0.2,random_state=0)\n",
    "\n",
    "    X_trainval = data[0].loc[trainval_idx]\n",
    "    X_test = data[0].loc[test_idx]\n",
    "\n",
    "    y_trainval = sparse.lil_matrix(target.loc[trainval_idx])\n",
    "    y_test = sparse.lil_matrix(target.loc[test_idx])\n",
    "\n",
    "    model_name = 'MLKNN'\n",
    "    best_score = 0\n",
    "    best_parameters ={}\n",
    "    for k in range(1,6):\n",
    "        for s in [0.000001,0.0001,0.01,1,100,1000]:\n",
    "            mlknn = MLkNN(k=k,s=s)\n",
    "            scores = cross_val_score(mlknn,X_trainval, y_trainval,cv=5,scoring='f1_samples')\n",
    "            score = np.mean(scores)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'k':k,'s':s}\n",
    "\n",
    "    mlknn = MLkNN(**best_parameters)\n",
    "    mlknn.fit(X_trainval,y_trainval)\n",
    "    test_score.append([vec[:-4],model_name,mlknn.score(X_test,y_test),best_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpmodel import gpmodel  # ?? What's this from?\n",
    "from gpmodel import gpkernel\n",
    "from gpmodel import gptools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
