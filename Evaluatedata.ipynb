{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #忽略不重要的warning\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictresult(predict_df):\n",
    "    row = 0\n",
    "    while row<1069: # 总样本量-1  599\n",
    "        y_test = predict_df.iloc[row+1:row+107] # 预测标签序号1-60\n",
    "        y_score = predict_df.iloc[row+108:row+214] # 预测概率序号61-120\n",
    "\n",
    "        y_test.reset_index(drop=True,inplace=True)\n",
    "        y_score.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        row += 214 # 一组样本个数 60*2\n",
    "        yield y_test,y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weight(y_test):\n",
    "    sw = []\n",
    "    for i in range(y_test.shape[1]):\n",
    "        sw.append(compute_sample_weight(class_weight='balanced',y=y_test[:,i]))\n",
    "    \n",
    "    sw = np.transpose(np.array(sw))\n",
    "    return sw\n",
    "\n",
    "def bieva(Eva_p,pred,Threshold):\n",
    "    breva = []\n",
    "    for y_test,y_score in pred:\n",
    "        y_test = np.array(y_test.astype('int'))\n",
    "        y_score = np.array(y_score.astype('float'))\n",
    "        y_pred = np.where(y_score>Threshold,1,0)        \n",
    "        sw = sample_weight(y_test)\n",
    "        \n",
    "        for i in range(y_test.shape[1]):\n",
    "            cm = confusion_matrix(y_test[:,i], y_pred[:,i],sample_weight=sw[:,i])\n",
    "\n",
    "            Accuracy = round(accuracy_score(y_test[:,i], y_pred[:,i],sample_weight=sw[:,i]),4)\n",
    "            Precision = round(precision_score(y_test[:,i], y_pred[:,i],sample_weight=sw[:,i]),4)\n",
    "            Recall = round(recall_score(y_test[:,i], y_pred[:,i],sample_weight=sw[:,i]),4)\n",
    "            f1 = round(f1_score(y_test[:,i], y_pred[:,i],sample_weight=sw[:,i]),4)\n",
    "            breva.append([Accuracy,Precision,Recall,f1])\n",
    "   \n",
    "    BReva_arr = np.array(breva).reshape(5,2,4) # # reshape(5,类别数,4)\n",
    "    BRmean_arr = np.around(np.mean(BReva_arr,0),2)\n",
    "    BRstd_arr = np.around(np.std(BReva_arr,0),4)\n",
    "    BR = np.concatenate((BRmean_arr,BRstd_arr),axis=1)\n",
    "    BR_df = pd.DataFrame(BR,columns=['Accuracy_m','Precision_m','Recall_m','F1 Score_m','Accuracy_s','Precision_s','Recall_s','F1 Score_s'])\n",
    "    BR_df.to_csv(Eva_p+'BinaryEvaluation.csv',mode='a') \n",
    "\n",
    "def auprc(Eva_p,pred):\n",
    "    roc = []\n",
    "    for y_test,y_score in pred:\n",
    "        y_label = y_test.columns\n",
    "        y_test = np.array(y_test.astype('int'))\n",
    "        y_score = np.array(y_score.astype('float'))\n",
    "        sw = sample_weight(y_test)\n",
    "        \n",
    "        for i in range(y_test.shape[1]):\n",
    "            average_precision = average_precision_score(y_test[:,i], y_score[:,i],sample_weight=sw[:,i])\n",
    "            AUC = roc_auc_score(y_test[:,i], y_score[:,i],sample_weight=sw[:,i])        \n",
    "            roc.append([round(average_precision,2),round(AUC,2)])\n",
    "    \n",
    "    ROC_arr = np.array(roc).reshape(5,2,2) # reshape(5,类别数,2)\n",
    "    ROCmean_arr = np.around(np.mean(ROC_arr,0),2)\n",
    "    ROCstd_arr = np.around(np.std(ROC_arr,0),4)\n",
    "    ROC = np.concatenate((ROCmean_arr,ROCstd_arr),axis=1)\n",
    "    ROC_df = pd.DataFrame(ROC,index=y_label,columns=['AUPR_m','AUC_m','AUPR_s','AUC_s'])\n",
    "    # ROC_df = pd.DataFrame(ROC.T,index=['AUPR_m','AUC_m','AUPR_s','AUC_s'],columns=y_label)\n",
    "    ROC_df.to_csv(Eva_p+'AUC_AUPR.csv',mode='a')    \n",
    "\n",
    "\n",
    "def hamloss(Eva_p,pred,Threshold):\n",
    "    hmloss = []\n",
    "    for y_test,y_score in pred:\n",
    "        y_test = np.array(y_test.astype('int'))\n",
    "        y_score = np.array(y_score.astype('float'))\n",
    "        y_pred = np.where(y_score>Threshold,1,0)\n",
    "        sw = sample_weight(y_test)\n",
    "        \n",
    "        hmloss.append(hamming_loss(y_test,y_pred,sw))\n",
    "    \n",
    "    HM_mean = round(np.mean(hmloss),2)\n",
    "    HM_std = round(np.std(hmloss),4)\n",
    "    HM = np.array([HM_mean, HM_std]).reshape(1,2)\n",
    "    HM_df = pd.DataFrame(HM,columns=['Hamming Loss_m','Hamming Loss_s'])\n",
    "    HM_df.to_csv(Eva_p+'HammingLoss.csv',mode='a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dir = '/home/dqw_lyt/LYT_Task2/script/ISTH_RJ_mmc_result/predict/94D/f1_loo_2_3/' \n",
    "\n",
    "\n",
    "model_c = ['test_BinaryRelevance.csv',\n",
    "            'test_ClassifierChain.csv',\n",
    "            'test_LabelPowerset.csv',\n",
    "            'test_MLkNN.csv',\n",
    "            'test_RakelD.csv']\n",
    "\n",
    "for csv in model_c:\n",
    "    predict_p = predict_dir + '/' + csv\n",
    "    predict_df = pd.read_csv(predict_p,header=None)\n",
    "    model_n = csv[5:-4]\n",
    "    \n",
    "    Eva_p = predict_dir + model_n + '/'\n",
    "\n",
    "    THRESHOLD = [0.5,0.4,0.35,0.3,0.25]\n",
    "    for Threshold in THRESHOLD:\n",
    "        pred = predictresult(predict_df)\n",
    "        bieva(Eva_p,pred,Threshold)\n",
    "\n",
    "    pred = predictresult(predict_df)\n",
    "    auprc(Eva_p,pred)\n",
    "    \n",
    "    THRESHOLD = [0.5,0.4,0.35,0.3,0.25]\n",
    "    for Threshold in THRESHOLD:\n",
    "        pred = predictresult(predict_df)\n",
    "        hamloss(Eva_p,pred,Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
